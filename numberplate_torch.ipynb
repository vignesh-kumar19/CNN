{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "numberplate_torch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkOT_lx7CUD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/tridhlj6xjqom90/anpr_ocr-1790.zip?dl=0\n",
        "!wget https://www.dropbox.com/s/gcs7wxsc847xh2h/numbers.JPG?dl=0\n",
        "!mv numbers.JPG?dl=0 numbers.JPG\n",
        "!wget https://www.dropbox.com/s/52mptr26gpl8foo/bill-out.PNG?dl=0\n",
        "!mv bill-out.PNG?dl=0 bill-out.PNG\n",
        "!unzip anpr_ocr-1790.zip?dl=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjD9nm2_CkCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyalcLTip6Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpkKo17fFaJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = \"train/anpr_ocr/train/img/\"\n",
        "x0 = []\n",
        "y0 = []\n",
        "for i in os.listdir(dataset_path):\n",
        "    image = cv2.imread(dataset_path + i)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (128, 32))\n",
        "    # plt.imshow(image)\n",
        "    image = image.astype(np.float32)\n",
        "    x0.append(image)\n",
        "    y0.append(i.split('.')[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Riz_R4sNOFQV",
        "colab_type": "code",
        "outputId": "db2ec3e2-7790-4060-b9ae-7ccaed455ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "# Label format \n",
        "# ['_', '3',  'O',  '1',  'E',  'P',  '7',  '9',  '0',  'X',  '2',  'T',  '6',  'Y',  'M',  'A',  'C',  'B',  '5',  '8',  'H',  '4',  'K']\n",
        "# import itertools\n",
        "# charList = [\"_\"]\n",
        "# charList.extend(list(set(itertools.chain(*y0))))\n",
        "charList = ['_'] + list(map(str, range(0, 10))) + list(string.ascii_uppercase)\n",
        "charList, len(charList)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['_',\n",
              "  '0',\n",
              "  '1',\n",
              "  '2',\n",
              "  '3',\n",
              "  '4',\n",
              "  '5',\n",
              "  '6',\n",
              "  '7',\n",
              "  '8',\n",
              "  '9',\n",
              "  'A',\n",
              "  'B',\n",
              "  'C',\n",
              "  'D',\n",
              "  'E',\n",
              "  'F',\n",
              "  'G',\n",
              "  'H',\n",
              "  'I',\n",
              "  'J',\n",
              "  'K',\n",
              "  'L',\n",
              "  'M',\n",
              "  'N',\n",
              "  'O',\n",
              "  'P',\n",
              "  'Q',\n",
              "  'R',\n",
              "  'S',\n",
              "  'T',\n",
              "  'U',\n",
              "  'V',\n",
              "  'W',\n",
              "  'X',\n",
              "  'Y',\n",
              "  'Z'],\n",
              " 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHwuRCw2RKVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = max([len(i) for i in y0])\n",
        "# max_len = 32\n",
        "targets = []\n",
        "for i in y0:\n",
        "    seq = list(map(lambda x0: charList.index(x0), i))\n",
        "    while len(seq) < max_len:\n",
        "        seq.append(0)\n",
        "    targets.append(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzgmKEp4xw3r",
        "colab_type": "code",
        "outputId": "8e1cdeaf-cef3-4e94-f373-d7e5f980c866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.asarray(x0).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10281, 32, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox2yUjDvHeX8",
        "colab_type": "code",
        "outputId": "88334310-613a-4c0e-8167-ff6a94f00547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# x0 = np.asarray(x0).reshape(10281, 1, 64, 128)\n",
        "x0 = np.asarray(x0).reshape(10281, 1, 32, 128)\n",
        "# x0 = np.asarray(x0)\n",
        "targets = np.asarray(targets)\n",
        "x0 = x0/255\n",
        "x0.shape, targets.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10281, 1, 32, 128), (10281, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYQwAShtt_vD",
        "colab_type": "code",
        "outputId": "ca1017dc-2a56-424e-fffd-e0335bb1b060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "targets[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([34,  3,  1,  6, 15, 21,  1, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c61sGd7uJoJ9",
        "colab_type": "code",
        "outputId": "b28d1ff7-6410-41c5-b7ed-3e4d1b7572e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x2 = torch.from_numpy(x0)\n",
        "y2 = torch.from_numpy(targets)\n",
        "input_lengths = torch.full(size=(10281,), fill_value=32, dtype=torch.long)\n",
        "# input_lengths = torch.full(size=(10281,), fill_value=80, dtype=torch.long)\n",
        "target_lengths = torch.full(size=(10281,), fill_value=8, dtype=torch.long)\n",
        "input_lengths, target_lengths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([37, 37, 37,  ..., 37, 37, 37]), tensor([8, 8, 8,  ..., 8, 8, 8]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gksyuEGsQTDs",
        "colab_type": "code",
        "outputId": "70f8f915-cc9d-4882-c3c9-c4d03c4d99e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y2[0:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[34,  3,  1,  6, 15, 21,  1, 10],\n",
              "        [12,  1,  3,  8, 34, 35,  3,  4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uig0pL6MgCZT",
        "colab_type": "text"
      },
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuBAukRlhwvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OCR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=(1, 1)) # (N, Channels, Height, Width)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=(1, 1)) # (N, Channels, Height, Width)\n",
        "#         self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=(1, 1)) # (N, Channels, Height, Width)\n",
        "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(3, 3), padding=(1, 1)) # (N, Channels, Height, Width)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=(1, 1)) # (N, Channels, Height, Width)\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=(1, 1)) # (N, Channels, Height, Width)\n",
        "        self.gru1 = nn.GRU(input_size=256, hidden_size=256, num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.gru2 = nn.GRU(input_size=256, hidden_size=256, num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.linear = nn.Linear(512, len(charList))\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=(1, 1)) # (N, Channels, Height, Width)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=(1, 1)) # (N, Channels, Height, Width)\n",
        "#         self.dense1 = nn.Linear(16*16, 32)\n",
        "#         self.gru1 = nn.GRU(input_size=32, hidden_size=512, num_layers=1, batch_first=True, bidirectional=True)\n",
        "#         self.gru2 = nn.GRU(input_size=512, hidden_size=512, num_layers=1, batch_first=True, bidirectional=True)\n",
        "#         self.dense2 = nn.Linear(1024, len(charList))\n",
        "#         self.softmax = nn.Softmax(dim=-1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "#         conv1 = F.relu(self.conv1(x))\n",
        "# #         print(\"Conv1 shape:\", conv1.shape)\n",
        "#         pool1 = F.max_pool2d(conv1, 2, 2)\n",
        "# #         print(\"Pool1 shape:\", pool1.shape)\n",
        "#         conv2 = F.relu(self.conv2(pool1))\n",
        "# #         print(\"Conv2 Shape:\", conv2.shape)\n",
        "#         pool2 = F.max_pool2d(conv2, 2, 2)\n",
        "# #         print(\"Pool2 shape\", pool2.shape)\n",
        "#         reshaped = pool2.view(-1, 32, 16*16)\n",
        "# #         print(\"Reshape shape\", reshaped.shape)\n",
        "# #         reshaped = reshaped.permute(0, 2, 1)\n",
        "# #         print(\"Permuted shape\", reshaped.shape)\n",
        "#         dense1 = F.relu(self.dense1(reshaped))\n",
        "#         gru1_output, (gru1_hidden, gru1_cell) = self.gru1(dense1)\n",
        "# #         print(\"Gru1 output shape:\", gru1_output.shape)\n",
        "#         gru1_shape = gru1_output.shape\n",
        "#         gru1_reshaped = gru1_output.view(gru1_shape[0], gru1_shape[1], 2, 512)\n",
        "# #         print(\"Gru1 shape:\", gru1_reshaped.shape)\n",
        "#         gru1_fwd = gru1_reshaped[:, :, 0, :]\n",
        "# #         print(\"GRU1 fwd shape:\", gru1_fwd.shape)\n",
        "#         gru1_bwd = gru1_reshaped[:, :, 1, :]\n",
        "# #         print(\"GRU1 bwd shape:\", gru1_bwd.shape)\n",
        "#         gru1 = gru1_fwd + gru1_bwd\n",
        "# #         print(\"GRU1 shape:\", gru1.shape)\n",
        "#         gru2_output, (gru2_hidden, gru2_cell) = self.gru2(gru1)\n",
        "# #         print(\"GRU2 output shape:\", gru2_output.shape)\n",
        "#         dense2 = F.relu(self.dense2(gru2_output))\n",
        "\n",
        "# #         print(\"Dense shape: \", dense2.shape)\n",
        "# #         output = self.softmax(dense2)\n",
        "#         output = dense2\n",
        "\n",
        "# #         print(\"Output shape: \", dense2.shape)\n",
        "#         output_permuted = output.view(output.shape[1], output.shape[0], output.shape[2])\n",
        "# #         print(\"Permuted shape:\", output_permuted.shape)\n",
        "#         return output_permuted\n",
        "        \n",
        "        \n",
        "        \n",
        "        # print(\"Input shape:\", x.shape)\n",
        "#         conv1 = F.relu(self.conv1(x))\n",
        "#         print(\"Conv1 shape:\", conv1.shape)\n",
        "#         pool1 = F.max_pool2d(conv1, 2, 2)\n",
        "#         print(\"Pool1 shape:\", pool1.shape)\n",
        "#         conv2 = F.relu(self.conv2(pool1))\n",
        "#         print(\"Conv2 shape:\", conv2.shape)\n",
        "#         pool2 = F.max_pool2d(conv2, 2, 2)\n",
        "#         print(\"Pool2 shape:\", pool2.shape)\n",
        "#         conv3 = F.relu(self.conv3(pool2))\n",
        "        conv3 = F.relu(self.conv3(x))\n",
        "        # print(\"Conv3 shape:\", conv3.shape)\n",
        "        pool3 = F.max_pool2d(conv3, 2, 2)\n",
        "        # print(\"Pool3 shape:\", pool3.shape)\n",
        "        conv4 = F.relu(self.conv4(pool3))\n",
        "        # print(\"Conv4 shape:\", conv4.shape)\n",
        "        pool4 = F.max_pool2d(conv4, 2, 4)\n",
        "        # print(\"Pool4 shape:\", pool4.shape)\n",
        "        fc = pool4.view(-1, 2*16, 256)\n",
        "        # print(\"FC shape:\", fc.shape)\n",
        "        gru1_output, (gru1_hidden, gru1_cell) = self.gru1(fc)\n",
        "        # print(\"GRU1 output:\", gru1_output.shape)\n",
        "        gru_reshaped = gru1_output.view(-1, 32, 2, 256)\n",
        "        # print(\"GRU1 reshaped shape:\", gru_reshaped.shape)\n",
        "        gru_fwd = gru_reshaped[:, :, 0, :]\n",
        "        # print(\"GRU FWD shape:\", gru_fwd.shape)\n",
        "        gru_bwd = gru_reshaped[:, :, 1, :]\n",
        "        # print(\"GRU BWD shape:\", gru_bwd.shape)\n",
        "        gru1 = gru_fwd + gru_bwd\n",
        "        # print(\"Gru1 shape:\", gru1.shape)\n",
        "        gru2_output, (gru2_hidden, gru2_cell) = self.gru2(gru1)\n",
        "        # print(\"GRU2 output shape:\", gru2_output.shape)\n",
        "        dense = self.linear(gru2_output)\n",
        "        # print(\"Dense shape:\", dense.shape)\n",
        "        output = F.relu(dense)\n",
        "#         output = self.softmax(dense)\n",
        "        # print(\"Ouptut Shape:\", output.shape)\n",
        "        return output.permute(1, 0, 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5knM0kP70WzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = OCR().to(device)\n",
        "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.001)\n",
        "criterion = nn.CTCLoss(blank=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36sr9ZSW1YxD",
        "colab_type": "code",
        "outputId": "e7e62cc0-5039-4a65-f549-d93828ae650d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OCR(\n",
              "  (conv3): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (gru1): GRU(256, 256, batch_first=True, bidirectional=True)\n",
              "  (gru2): GRU(256, 256, batch_first=True, bidirectional=True)\n",
              "  (linear): Linear(in_features=512, out_features=37, bias=True)\n",
              "  (softmax): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMXms2WpgkXu",
        "colab_type": "text"
      },
      "source": [
        "# Create Traning dataset batch by batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-sDjyp5MrHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class training_data():\n",
        "    def __init__(self, batch_size):\n",
        "        self.current_index = 0\n",
        "        self.len = len(x2)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def next_samples(self):\n",
        "        \n",
        "        x = x2[self.current_index:self.current_index+self.batch_size]\n",
        "        y = y2[self.current_index:self.current_index+self.batch_size]\n",
        "        x_lengths = input_lengths[self.current_index:self.current_index+self.batch_size]\n",
        "        y_lengths = target_lengths[self.current_index:self.current_index+self.batch_size]\n",
        "        # x_lengths = torch.full(size=(self.batch_size,), fill_value=len(charList), dtype=torch.long)\n",
        "        # y_lengths = torch.full(size=(self.batch_size,), fill_value=8, dtype=torch.long)\n",
        "        \n",
        "        \n",
        "        self.current_index = self.current_index + self.batch_size\n",
        "        \n",
        "        if self.current_index >= self.len:\n",
        "            self.current_index = 0\n",
        "        \n",
        "        return x, y, x_lengths, y_lengths\n",
        "            \n",
        "            \n",
        "    def next_batch(self):\n",
        "        # print(\"Data between {} and {}\".format(self.current_index, self.current_index+self.batch_size))\n",
        "        x, y, x_lengths, y_lengths = self.next_samples()\n",
        "        return (x, y, x_lengths, y_lengths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1w2eTAcMq0B",
        "colab_type": "code",
        "outputId": "7b71de10-1438-464d-a87f-303c43861437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "input_lengths[:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
              "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
              "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
              "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
              "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
              "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfSUrdgIbHHL",
        "colab_type": "code",
        "outputId": "4c2b7644-7b04-4174-d1b7-4857239b0341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x2) // 2500"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Piq2ooT8gooj",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlDrRmc92TV-",
        "colab_type": "code",
        "outputId": "e7166983-6dfd-4153-9455-daebf5b17ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 1000\n",
        "loss_history = []\n",
        "acc_history = []\n",
        "batch_size = 128\n",
        "training_dataset = training_data(batch_size)\n",
        "\n",
        "# x, y, x_lens, y_lens = training_dataset.next_batch()\n",
        "# x, y, x_lens, y_lens = x2[:100], y2[:100], input_lengths[:100], target_lengths[:100]\n",
        "\n",
        "# x = x.to(device)\n",
        "# y = y.to(device)\n",
        "\n",
        "# x_lens = x_lens.to(device)\n",
        "# y_lens = y_lens.to(device)\n",
        "\n",
        "for i in range(epochs):\n",
        "    print(\"***************** Epochs {} *****************\".format(i))\n",
        "    for batch in  range(len(x2)//batch_size):\n",
        "        # print(\"Batch:\", batch)\n",
        "        x, y, x_lens, y_lens = training_dataset.next_batch()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x_lens = x_lens.to(device)\n",
        "        y_lens = y_lens.to(device)\n",
        "        print(x)\n",
        "        print(y)\n",
        "        print(x_lens)\n",
        "        print(y_lens)\n",
        "    #     running_loss = 0.0\n",
        "    #     for j in range(len(x2)//batch_size):\n",
        "    #         print(j)\n",
        "    #         print(x_lens)\n",
        "        \n",
        "        \n",
        "        pred = model.forward(x)\n",
        "        \n",
        "        # print(pred.shape)\n",
        "        # print(y.shape)\n",
        "        pred = pred.log_softmax(2)\n",
        "        print(pred.shape)\n",
        "    #         print(pred.shape)\n",
        "    #         print(y.shape)\n",
        "    #         print(x_lens.shape)\n",
        "    #         print(y_lens.shape)\n",
        "        loss = criterion(pred[:, :, :], y, x_lens, y_lens)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_history.append(loss.item())\n",
        "        if i % 100 == 0:\n",
        "            print(loss.item())\n",
        "    #         print(loss.item())\n",
        "    #     running_loss += loss.item()\n",
        "        \n",
        "    #     epoch_loss = running_loss * batch_size / len(x)\n",
        "    #     loss_history.append(epoch_loss)\n",
        "    #     print(\"Loss: \", epoch_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***************** Epochs 0 *****************\n",
            "tensor([[[[0.7765, 0.4627, 0.3647,  ..., 0.3647, 0.4627, 0.7765],\n",
            "          [0.2588, 0.1686, 0.1333,  ..., 0.1333, 0.1686, 0.2588],\n",
            "          [0.0980, 0.1765, 0.5294,  ..., 0.5294, 0.1765, 0.0980],\n",
            "          ...,\n",
            "          [0.1569, 0.1294, 0.2549,  ..., 0.2549, 0.1294, 0.1569],\n",
            "          [0.5098, 0.1373, 0.1059,  ..., 0.1059, 0.1373, 0.5098],\n",
            "          [0.7333, 0.6863, 0.6667,  ..., 0.6667, 0.6863, 0.7333]]],\n",
            "\n",
            "\n",
            "        [[[0.7765, 0.4627, 0.3647,  ..., 0.3647, 0.4627, 0.7765],\n",
            "          [0.2588, 0.1686, 0.1333,  ..., 0.1333, 0.1686, 0.2588],\n",
            "          [0.0980, 0.1765, 0.5294,  ..., 0.5294, 0.1765, 0.0980],\n",
            "          ...,\n",
            "          [0.1569, 0.1294, 0.2549,  ..., 0.2549, 0.1294, 0.1569],\n",
            "          [0.5098, 0.1373, 0.1059,  ..., 0.1059, 0.1373, 0.5098],\n",
            "          [0.7333, 0.6863, 0.6667,  ..., 0.6667, 0.6863, 0.7333]]],\n",
            "\n",
            "\n",
            "        [[[0.7765, 0.4627, 0.3647,  ..., 0.3647, 0.4627, 0.7765],\n",
            "          [0.2588, 0.1686, 0.1333,  ..., 0.1333, 0.1686, 0.2588],\n",
            "          [0.0980, 0.1765, 0.5294,  ..., 0.5294, 0.1765, 0.0980],\n",
            "          ...,\n",
            "          [0.1569, 0.1294, 0.2549,  ..., 0.2549, 0.1294, 0.1569],\n",
            "          [0.5098, 0.1373, 0.1059,  ..., 0.1059, 0.1373, 0.5098],\n",
            "          [0.7333, 0.6863, 0.6667,  ..., 0.6667, 0.6863, 0.7333]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.7765, 0.4627, 0.3647,  ..., 0.3647, 0.4627, 0.7765],\n",
            "          [0.2588, 0.1686, 0.1333,  ..., 0.1333, 0.1686, 0.2588],\n",
            "          [0.0980, 0.1765, 0.5294,  ..., 0.5294, 0.1765, 0.0980],\n",
            "          ...,\n",
            "          [0.1569, 0.1294, 0.2549,  ..., 0.2549, 0.1294, 0.1569],\n",
            "          [0.5098, 0.1373, 0.1059,  ..., 0.1059, 0.1373, 0.5098],\n",
            "          [0.7333, 0.6863, 0.6667,  ..., 0.6667, 0.6863, 0.7333]]],\n",
            "\n",
            "\n",
            "        [[[0.7765, 0.4627, 0.3647,  ..., 0.3647, 0.4627, 0.7765],\n",
            "          [0.2588, 0.1686, 0.1333,  ..., 0.1333, 0.1686, 0.2588],\n",
            "          [0.0980, 0.1765, 0.5294,  ..., 0.5294, 0.1765, 0.0980],\n",
            "          ...,\n",
            "          [0.1569, 0.1294, 0.2549,  ..., 0.2549, 0.1294, 0.1569],\n",
            "          [0.5098, 0.1373, 0.1059,  ..., 0.1059, 0.1373, 0.5098],\n",
            "          [0.7333, 0.6863, 0.6667,  ..., 0.6667, 0.6863, 0.7333]]],\n",
            "\n",
            "\n",
            "        [[[0.7765, 0.4627, 0.3647,  ..., 0.3647, 0.4627, 0.7765],\n",
            "          [0.2588, 0.1686, 0.1333,  ..., 0.1333, 0.1686, 0.2588],\n",
            "          [0.0980, 0.1765, 0.5294,  ..., 0.5294, 0.1765, 0.0980],\n",
            "          ...,\n",
            "          [0.1569, 0.1294, 0.2549,  ..., 0.2549, 0.1294, 0.1569],\n",
            "          [0.5098, 0.1373, 0.1059,  ..., 0.1059, 0.1373, 0.5098],\n",
            "          [0.7333, 0.6863, 0.6667,  ..., 0.6667, 0.6863, 0.7333]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[34,  3,  1,  ..., 21,  1, 10],\n",
            "        [12,  1,  3,  ..., 35,  3,  4],\n",
            "        [35,  8,  5,  ..., 18,  6,  7],\n",
            "        ...,\n",
            "        [15,  5,  3,  ..., 11,  1,  4],\n",
            "        [21,  9,  3,  ..., 35,  8,  9],\n",
            "        [26,  5,  5,  ..., 30,  5,  4]], device='cuda:0')\n",
            "tensor([37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
            "        37, 37], device='cuda:0')\n",
            "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
            "torch.Size([32, 128, 37])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-9beb14f7d33f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#         print(x_lens.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#         print(y_lens.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, log_probs, targets, input_lengths, target_lengths)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,\n\u001b[0;32m-> 1295\u001b[0;31m                           self.zero_infinity)\n\u001b[0m\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;31m# TODO: L1HingeEmbeddingCriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mctc_loss\u001b[0;34m(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)\u001b[0m\n\u001b[1;32m   1779\u001b[0m     \"\"\"\n\u001b[1;32m   1780\u001b[0m     return torch.ctc_loss(log_probs, targets, input_lengths, target_lengths, blank, _Reduction.get_enum(reduction),\n\u001b[0;32m-> 1781\u001b[0;31m                           zero_infinity)\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected input_lengths to have value at most 32, but got value 37 (while checking arguments for ctc_loss_gpu)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97WK5o2_fx_U",
        "colab_type": "text"
      },
      "source": [
        "# Predict Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dGVui4X1uQEc",
        "colab": {}
      },
      "source": [
        "def final_output(predicted_output):\n",
        "    predicted_output = [charList[i[0]] for i in predicted_output]\n",
        "    print(predicted_output)\n",
        "    output = ['_']\n",
        "    for i in predicted_output:\n",
        "        if i == output[-1]:\n",
        "            continue\n",
        "        output.append(i)\n",
        "\n",
        "    output = [i for i in output if i != '_']\n",
        "    return ''.join(output[:8])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVqTabhWqyqC",
        "colab_type": "code",
        "outputId": "d173b594-483e-40ae-95d3-af5938adda2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "image_index = -4\n",
        "plt.imshow(x[image_index].view(32, 128).to(torch.device('cpu')))\n",
        "plt.plot()\n",
        "print(\"Input Image: \")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Image: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB1CAYAAABXo7o4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhiIDuCAIQobyf6FScgAwVAXjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3c8244a5-b1d6-43c4-9e7a-2c9fa3efeeb1",
        "id": "xq0paqCTt_eD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(\"Number in the number plate image:\", final_output(model.forward(x[image_index].view(1, 1, 32, 128).to(device)).argmax(-1).tolist()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B', '_', '_', '4', '_', '3', '_', '5', '_', '_', '_', '_', '_', '_', '_', '_', 'H', '_', 'P', '_', '_', '0', '7', '7', '7', '7', '7', '7', '7', '7', '7', '_']\n",
            "Number in the number plate image: B435HP07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oT9QZy9fj_6",
        "colab_type": "text"
      },
      "source": [
        "# Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsT27uEkweWB",
        "colab_type": "code",
        "outputId": "5b0c5e1c-27df-4840-b378-1dbc7e63f6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j95KgeFVwc3g",
        "colab_type": "code",
        "outputId": "4fb278f3-1ba1-4ec7-c682-0758b022e927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/Colab\\ Notebooks/weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numberplate_ocr_torch_1000.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nBlzpQBcz3C",
        "colab_type": "text"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYSrH9YKcyBN",
        "colab_type": "code",
        "outputId": "dfa81c68-4efa-47e0-f465-a90c0ef15bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "torch.save(model, '/content/gdrive/My Drive/Colab Notebooks/weights/numberplate_ocr_torch_{}.pt'.format(epochs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type OCR. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Softmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDbVpDZicx9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = torch.load('/content/gdrive/My Drive/Colab Notebooks/weights/numberplate_ocr_torch_1000.pt').to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWNBRQpxf0mQ",
        "colab_type": "text"
      },
      "source": [
        "# End loading page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQlRmkjEZ0JL",
        "colab_type": "code",
        "outputId": "e7d1d81d-cd53-4248-fa04-7b5f263235fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "assert False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMAeBm2Kf6yS",
        "colab_type": "text"
      },
      "source": [
        "# For CTC loss calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE-DGzWohtIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred.shape, y.shape, x_lengths.shape, y_lengths.shape\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEVgspEzR7-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T = 50      # Input sequence length\n",
        "C = 20      # Number of classes (including blank)\n",
        "N = 16      # Batch size\n",
        "S = 30      # Target sequence length of longest target in batch\n",
        "S_min = 10  # Minimum target length, for demonstration purposes\n",
        "\n",
        "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
        "# input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
        "input = Variable(torch.randn(T, N, C).log_softmax(2), requires_grad=True)\n",
        "\n",
        "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
        "target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
        "\n",
        "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
        "target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
        "ctc_loss = nn.CTCLoss()\n",
        "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFI-ASTRqSrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input.shape, target.shape, input_lengths.shape, target_lengths.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQxP3qvPg-Va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input[:, 0, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9DjMkfmKiZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUT6tih3K3hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow((x[0] * 255).view(64, 128).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSpe_9bdNVqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[charList[i] for i in y[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpLS9SINQdnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Qbsve5V-aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}